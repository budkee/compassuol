{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WrRfqfl0MCv",
    "tags": []
   },
   "source": [
    "# Jupyter | Hub\n",
    "\n",
    "## Spark e AWS Glue\n",
    "\n",
    "### Documentações\n",
    "\n",
    "- [Gerenciar partições para saída de ETL no AWS Glue](https://docs.aws.amazon.com/pt_br/glue/latest/dg/aws-glue-programming-etl-partitions.html)\n",
    "- [Program AWS Glue ETL scripts in PySpark](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python.html)\n",
    "- [Getting started with Apache Spark on Amazon Athena](https://docs.aws.amazon.com/athena/latest/ug/notebooks-spark-getting-started.html)\n",
    "\n",
    "## Setup do ambiente de desenvolvimento\n",
    "\n",
    "- [AWS Glue Docker Image | Dev](https://aws.amazon.com/pt/blogs/big-data/develop-and-test-aws-glue-version-3-0-jobs-locally-using-a-docker-container/)\n",
    "\n",
    "### Último comando utilizado \n",
    "    \n",
    "        docker run -it -v ~/.aws:/home/glue_user/.aws -v $JUPYTER_WORKSPACE_LOCATION:/home/glue_user/workspace/jupyter_workspace/ -e AWS_PROFILE=default -e DISABLE_SSL=true -p 8888:8888 --name glue_jupyter_lab amazon/aws-glue-libs:glue_libs_4.0.0_image_01 /home/glue_user/jupyter/jupyter_start.sh\n",
    "\n",
    "\n",
    "### Comando Docker | Prod\n",
    "\n",
    "        docker run -itd -p <port_on_host>:<port_on_container_either_8888_or_8080> -p 4040:4040 -v ~/.aws:/home/glue_user/.aws -v <DiretorioOndeVaiSerArmazenadoOsNotebooks>:/home/glue_user/workspace/jupyter_workspace> -e AWS_PROFILE=<credential_setup_to_access_AWS_resources> --name <container_name> amazon/aws-glue-libs:glue_libs_4.0.0_image_01 <command_to_start_notebook_server>\n",
    "    \n",
    "- `-v ~/.aws:</root/.aws:rw>`: setar permissão de ler e escrever daquele diretório\n",
    "\n",
    "### Comando Docker | Dev Spark UI\n",
    "\n",
    "    docker run -it -v <ArquivosConfigAwsCLI>:/home/glue_user/.aws -v <DiretorioOndeVaiSerArmazenadoOsNotebooks>:/home/glue_user/workspace/jupyter_workspace/ -e AWS_PROFILE=<NomePerfilAWS> -e DISABLE_SSL=true --rm -p 4040:4040 -p 18080:18080 -p 8998:8998 -p 8888:8888 --name glue_jupyter_lab amazon/aws-glue-libs:aws-glue-libs:glue_libs_4.0.0_image_01 /home/glue_user/jupyter/jupyter_start.sh\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Executando scripts \n",
    "\n",
    "### Job Local | Pyspark\n",
    "\n",
    "- O script para este caso deve ser executado dentro do diretório do projeto, devendo ter o Spark previamente instalado na sua máquina. \n",
    "\n",
    "#### Comandos utilizados\n",
    "\n",
    "- Run: `spark-submit --master local caminho/para/seu-script.py argumento1 argumento2`\n",
    "- Log: será apresentado logo em seguida.\n",
    "\n",
    "### Job Local | AWS GLue\n",
    "\n",
    "- O script deve ser executado no terminal do container Docker, com as credenciais AWS já configuradas. \n",
    "\n",
    "#### Comandos utilizados\n",
    "\n",
    "- Run: `aws glue start-job-run --job-name SEU_NOME_DE_JOB`\n",
    "- Log (json): `aws glue get-job-run --job-name MeuJobGlue --run-id SEU_ID_DE_EXECUCAO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7adUyrx0Qii"
   },
   "outputs": [],
   "source": [
    "import os # Sistema operacional \n",
    "import sys # Funções e variáveis da shell do Python\n",
    "import getopt # Criação de opções de entrada pela CLI\n",
    "\n",
    "# Spark\n",
    "import pyspark  \n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import * \n",
    "\n",
    "# SparkSession\n",
    "spark = SparkSession.builder.appName(\"App_1\").getOrCreate()\n",
    "\n",
    "# SparkContext\n",
    "#sc = SparkContext()\n",
    "\n",
    "# Job\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    input_path = \"/Users/camilabudke/Desenvolvimento/jupyter/dados_brutos/nomes.csv\"\n",
    "    target_path = \"/Users/camilabudke/Desenvolvimento/jupyter/dados_processados/nomes\"\n",
    "    \n",
    "    esquema = \"nome STRING, sexo STRING, total INT, ano INT\"\n",
    "    \n",
    "    nomes = spark.read.csv(input_path, header=True, schema=esquema)\n",
    "    #nomes = spark.read.csv(sys.argv[1:], header=True, schema=esquema)\n",
    "    \n",
    "    \n",
    "    # Transformação: Contagem das linhas do DataFrame\n",
    "    linhas = nomes.count()\n",
    "    \n",
    "    # 1. Colocar os valores da coluna 'nome' em Maiúsculo\n",
    "    from pyspark.sql.functions import upper\n",
    "    nome_maiusc_col = nomes.withColumn(\"nome\", upper(nomes[\"nome\"]))\n",
    "    \n",
    "    # Output\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n Número de linhas: \", linhas)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #nome_maiusc_col.write.format(\"console\").save()\n",
    "    \n",
    "    # Salvar a transformação particionada por sexo e ano\n",
    "    # nome_maiusc_col.write.partitionBy(\"sexo\", \"ano\").json(target_path)\n",
    "    nome_maiusc_col.write.partitionBy(\"sexo\", \"ano\").mode('overwrite').json(target_path)\n",
    "\n",
    "    # Fim da aplicação\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sem API\n",
    "caminho_texto = \"./README.md\"\n",
    "caminho_csv = \"./nomes.csv\"\n",
    "#nomes = spark.read.format(\"csv\").load(caminho_csv)\n",
    "\n",
    "# Com API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Jobs\n",
    "\n",
    "- [Conta palavras de um arquivo de texto | Job 1](lab/jobs/job_conta_palavras.ipynb)\n",
    "- [Colunas em maiúsculo particionadas | Job 2](lab/jobs/glue_lab.ipynb)\n",
    "- []()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
